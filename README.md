<h1 align="center">spanlp</h1>

<p align="center">
  <br>
  <i>spanlp es una librer√≠a escrita en Python para detectar, censurar  y limpiar groser√≠as, <br>
      vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en <strong>Espa√±ol</strong>.
    </i>
  <br>
  
  <p align="center">
    <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/version-v1.1.0-green"/>
    </a>
    <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/status-stable-blue"/>
    </a>
  <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/release-v1.1.0-brightgreen"/>
    </a>
    <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/test--pypi-v0.0.7-yellow"/>
    </a>
  <a href="https://test.pypi.org/project/spanlp/">
      <img src="https://img.shields.io/badge/license-MIT-brightgreen"/>
    </a>
  </p>
  
  <p align="center">
    <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/jfreddypuentes/spanlp?style=social">
  </p>
</p>

<hr>

## Indice
- [Indice](#indice)
- [Sobre la librer√≠a](#sobre-la-librer√≠a)
- [Casos de uso](#casos-de-uso)
- [Status Desarrollo](#status-desarrollo)
- [Instalaci√≥n](#instalaci√≥n)
- [Funcionamiento](#funcionamiento)
  - [Uso b√°sico](#uso-basico)
  - [Uso avanzado](#uso-avanzado)
  - [Pre-procesamiento de datos](#preprocesamiento-de-texto)
- [Testing](#testing)
- [Reportar un bug](#reportar-un-bug)
- [Contribuidorxs](#contribuidorxs)
- [Contacto](#contacto)

<hr>

## Sobre la librer√≠a
spanlp es una librer√≠a escrita en Python para detecci√≥n de groser√≠as, vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en Espa√±ol. Puedes usar la librer√≠a y aplicarla a palabras de cualquiera de los m√°s de **20 paises** de habla hispana.

Incluye:
1. Argentina üá¶üá∑
2. Bolivia üáßüá¥
3. Chile üá®üá±
4. Colombia üá®üá¥
5. Costa Rica üá®üá∑
6. Cuba üá®üá∫
7. Ecuador üá™üá®
8. El Salvador üá∏üáª
9. Espa√±a üá™üá∏
10. Guatemala üá¨üáπ
11. Guinea Ecuatorial üá¨üá∂
12. Honduras üá≠üá≥
13. M√©xico üá≤üáΩ
14. Nicaragua üá≥üáÆ
15. Panam√° üáµüá¶
16. Paraguay üáµüáæ
17. Per√∫ üáµüá™
18. Puerto Rico üáµüá∑
19. Rep√∫blica Dominicana üá©üá¥
20. Uruguay üá∫üáæ
21. Venezuela üáªüá™

## Casos de uso
* Censurar vulgaridades en un texto.
* Detectar y censurar vulgaridades en una sala de chat en linea.
* Encontrar y censurar frases y palabras de odio, racismo, xenofia, bullying. (Se deben incluir como par√°metros)
* Censurar comentarios groseros o insultos en alg√∫n blog o aplicaci√≥n web o sitio web.
* Censurar malas palabras en un sistema de recolecci√≥n de opiniones, sugerencias, quejas y reclamos.
* Limpiar textos antes de ser publicados.
* Detectar y eliminar vulgaridades en textos que ser√°n leidos y/o vistos por ni√±os.
* Limpiar una base de datos con mucho texto.

## Status Desarrollo

| Funcionalidad                     | Desarrollo |   Pruebas   | Release  |
|-----------------------------------|------------|-------------|-----------
| Soporte de tokens con n√∫meros     |     ‚úì      |      ‚úì      | v0.0.5   |  
| Estrategias de limpieza de datos  |     ‚úì      |      ‚úì      | v0.0.5   |
| Completar dataset                 |     ‚úì      |      ‚úì      | v1.0.1   |
| Hamming                           |     ‚úì      |      ‚úì      | v1.0.2   |
| Levenstein                        |     ‚úì      |      ‚úì      | v1.1.0   |
| Bag distance                      |     -      |             |    -     |
| Sorensen-Dice coefficient         |     -      |             |    -     |
| Tversky index                     |     -      |             |    -     |
| Overlap index                     |     -      |             |    -     |
| Tanimoto distance                 |     -      |             |    -     |
| Ampliaci√≥n datasets               |  Progreso  |      -      |    -     |
| % de palabrotas en el texto       |     -      |      -      |    -     |


## Instalaci√≥n
Para instalar la √∫ltima versi√≥n use:
```console
pip install spanlp
```

Para instalar una versi√≥n espec√≠fica use (por ejemplo):
```
pip install spanlp==1.1.0
```

## Funcionamiento
Los algoritmos y modulos se personalizan de forma din√°mica y muy flexible. Veamos algunos usos.

### Uso b√°sico

Validar si una palabra o frase contiene o no una palabrota:
```python
from spanlp.palabrota import Palabrota
palabrota = Palabrota()
print(palabrota.contains_palabrota("Hola huevon c√≥mo est√°?"))
# salida: True
```

```python
from spanlp.palabrota import Palabrota
palabrota = Palabrota()
print(palabrota.contains_palabrota("Hola a todos ¬øc√≥mo est√°n?"))
# salida: False
```

Censurar una frase con los par√°metros por defecto:

```python
from spanlp.palabrota import Palabrota

palabrota = Palabrota()
print(palabrota.censor("Hola huevon c√≥mo est√°?"))

# salida: Hola !$%#@! c√≥mo est√°?
```

Censurar la misma frase, configurando car√°cteres propios

```python
from spanlp.palabrota import Palabrota

palabrota = Palabrota(censor_char="*")
print(palabrota.censor("Hola huevon como est√°?"))

# salida: Hola ****** c√≥mo est√°?
```

Censurar otra frase, configurando car√°cteres propios y pa√≠s

```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.COLOMBIA, Country.VENEZUELA])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola @@@@@@ @@@@@@ c√≥mo est√°?
```

Censuremos la misma frase pero solo con el pa√≠s de Venezuela
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.VENEZUELA])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola huevon @@@@@@ c√≥mo est√°?
```

Censuremos la misma frase pero incluyendo "huevon" al vocabulario de Venezuela
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.VENEZUELA], include=["huevon"])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola @@@@@@ @@@@@@ c√≥mo est√°?
```

Censuremos la misma frase incluyendo "huevon" al vocabulario de Venezuela y excluyendo "marico"
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="@", countries=[Country.VENEZUELA], include=["huevon"], exclude=["marico"])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: Hola huevon marico c√≥mo est√°?
```

Censuremos la misma frase incluyendo ""Hola" y "huevon" al vocabulario de Venezuela y excluyendo "marico"
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country

palabrota = Palabrota(censor_char="-", countries=[Country.VENEZUELA], include=["huevon"], exclude=["marico"])
print(palabrota.censor("Hola huevon marico c√≥mo est√°?"))

# salida: ---- ---- marico c√≥mo est√°?
```

### Uso Avanzado
El uso avanzado incluye usar metricas de distancia y similitud para encontrar, comparar, censurar palabras.
Estas son las metricas usadas a la fecha:
1. [ES-Indice de Jaccard](https://es.wikipedia.org/wiki/%C3%8Dndice_Jaccard) ([EN-Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index))
2. [ES-Similitud del coseno](https://es.wikipedia.org/wiki/Similitud_coseno) ([EN-Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity))
3. [ES-Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Levenshtein)([EN-Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance))
4. [ES-Damerau-Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Damerau-Levenshtein)([EN-Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance))

Censuremos la frase usando Cosine Similarity 
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import CosineSimilarity

palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=CosineSimilarity())
print(palabrota.censor("Hola huevo maric c√≥mo est√°?"))

# salida: Hola huevo ***** c√≥mo est√°?
```
A pesar de que "maric" no est√° en el dataset, al algoritmo la censur√≥ dado que por la m√©trica de distancia es muy similar. 


Censuremos la frase usando **Cosine Similarity** manipulando los par√°metros
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import CosineSimilarity

# Indicamos que tenga en cuenta palabras similares en al menos 30% y que normalice los datos (poner en minusculas, remover acentos)
cosine = CosineSimilarity(0.9, normalize=True) 
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=cosine)
print(palabrota.censor("Hola huevon MARIC c√≥mo est√°?"))

# salida: hola huevon ***** **** esta? => Censur√≥ "como" porque en el dataset est√° "cono" y son similares en m√°s del 90%
```

Censuremos la frase usando **JaccardIndex** con los par√°metros por defecto
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=JaccardIndex())
print(palabrota.censor("Hola huevo maric c√≥mo est√°?"))

# salida: Hola huevo ***** c√≥mo est√°?
```
El indice de Jaccard usa por defecto los siguientes par√°metros:
* `threshold=0.8` - Indica que censurar√° palabras con una similitud del 80% o m√°s.
* `normalize=False` - False indica que no pasar√° el texto a minuscula y no remover√° acentos.
* `n_gram=2` - Usa 2 subsecuencias de la palabra. (Ver [N-grama](https://es.wikipedia.org/wiki/N-grama))

Censuremos la frase usando **JaccardIndex** y modifiquemos los par√°metros
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.9, normalize=True, n_gram=1)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: hola huevon ****** **** vamos?
```

Ahora, sin normalizar los datos
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.9, normalize=False, n_gram=1)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: Hola huevon ****** c√≥mo vamos? => "moco" y "c√≥mo" ahora son muy diferentes.
```

Ahora, bajemos el `threshold` a `0.6`
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.6, normalize=False, n_gram=1)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: Hola ****** ****** c√≥mo vamos? => Ha censurado una palabra m√°s.
```

Aumentemos la cantidad de `n_gram` a `3` con el `threshold=0.7` y con `normalize=False`
```python
from spanlp.palabrota import Palabrota
from spanlp.domain.countries import Country
from spanlp.domain.strategies import JaccardIndex

jaccard = JaccardIndex(threshold=0.7, normalize=False, n_gram=3)
palabrota = Palabrota(censor_char="*", countries=[Country.VENEZUELA], distance_metric=jaccard)
print(palabrota.censor("Hola huevon marica c√≥mo vamos?"))

# salida: Hola huevon marica c√≥mo vamos? => No censur√≥ nada.
```

## Preprocesamiento de texto
Siempre ser√° necesario limpiar los datos antes de empezar a trabajar. Aqui te presento la clase `Preprocessing` y las 28 estrat√©gias de limpieza de datos.

¬øCuantas estrategias hay y cuales son?

Son 28 algoritmos y son:

1. `TextToLower` **input**: "HOLA QUE M√ÅS?" **output:** "hola que m√°s?"
2. `TextToUpper` **input:** "hola ¬øc√≥mo est√°n?" **output:** "HOLA ¬øC√ìMO EST√ÅN?"
3. `RemoveUnicodeCharacters` **input:** "hola √ßcomo ¬™van?" **output:** "hola como van"  ([Unicode characters](https://www.rapidtables.com/code/text/unicode-characters.html))
4. `NumbersToVowelsInLowerCase` **input:** "h0l4 qu3 t4l?" **ouput:** "hola que tal?"
5. `NumbersToVowelsInUpperCase` **input:** "H0l4 c0m0 v4n?" **output:** "HOlA cOmO vAn?"
6. `NumbersToConsonantsInLowerCase` **input:** "C0m0 e574n? 8i3n?" **output:** "Como estan? bien?"
7. `NumbersToConsonantsInUpperCase` **input:** "C0m0 e574n? 8i3n?" **output:** "COMO ESTAN? BIEN?"
8. `RemoveExtraSpaces` **input:** "Hola   como est√°n?   " **output:** "Hola como est√°n?"
9. `RemoveUserMentions` **input:** "Hola @channel como van?" **output:** "Hola como van?"
10. `RemoveUrls`  **input:** "Revisen este recurso https://github.com/jfreddypuentes/spanlp" **output:** "Revisen este recurso "
11. `RemoveHashtags` **input:** "Hola #equipo bienvenidos" **output:** "Hola  bienvenidos"
12. `RemoveTicks` **input:** "Hola, que' m√°s'" **output:** "Hola, que m√°s"
13. `RemoveBackTicks` **input:** "Hola, que` m√°s`" **output:** "Hola, que m√°s"
14. `RemovePunctuation`  **input:** "Mensaje...,con, puntos" **output:** "Mensaje con puntos"
15. `RemoveNumbers` **input:** "Hay 12 patacones  y 20 yucas" **output:** "Hay patacones y yucas"
16. `RemoveAccents` **input:** "La canci√≥n es una sensaci√≥n" **output:** "La cancion es una sensacion"
17. `RemoveStopWords` **input:** "La canci√≥n y la letra es buena" **output:** "canci√≥n letra buena"
18. `RemoveArticles` **input:** "La canci√≥n y la letra es buena" **output:** "canci√≥n y letra es buena"
19. `RemoveEmoticons` **input:** "Hola ;) como est√°s? XD" **output:** "Hola como est√°s?"
20. `RemovePronouns` **input:** "Yo pienso que ella deber√≠a ser como √©l" **output:** "pienso que deber√≠a ser como"
21. `RemoveAdverbs` **input:** "muchos a√±os despues frente al peloton de fusilamiento lentamente recordaba..." **output:** "muchos a√±os frente al peloton de fusilamiento recordaba..."
22. `RemoveConjunctions` **input:** "y entonces estaba programando aunque con sue√±o pero concentrado creando esta libreria" **output:** "entonces estaba programando con sue√±o concentrado creando esta libreria"
23. `RemovePrepositions` **input:** "ante todo es mejor cuidar a la naturaleza mediante buenas acciones. entre todos podemos." **output:** "todo es mejor cuidar la naturaleza buenas acciones. todos podemos."
24. `RemoveAdjectives` **input:** "la voz era tenebrosa y la noche estaba fria y oscura hasta que de pronto algo luminoso apareci√≥ y" **output:** "la voz era y la noche estaba y hasta que de pronto algo apareci√≥ y"
25. `RemoveHtmlTags` **input:** "Hola <strong>USUARIO</strong> que tal?" **output:** "Hola USUARIO que tal?"
26. `RemoveEmailAddress` **input:** "Hola Pepito, el correo es contacto@domain.com" **output:** "Hola Pepito, el correo es "
27. `ExpandAbbreviations` **input:** "pero xq tengo es3 si yo estaba bn en clase, ahora me duelen to2 los musculos" **output:** "pero por que tengo estres si yo estaba bien en clase, ahora me duelen todos los musculos"
28. `RemoveAbbreviations` **input:** "xfa pongase el tapabocas pq me da es3 verlo sin eso. to2 debemos cuidarnos. chas gracias. salu2" **output:** "pongase el tapabocas me da verlo sin eso. debemos cuidarnos. gracias."


La nueva clase `Preprocessing` implementa de manera flexible y din√°mica cualquier estrategia de limpieza de una manera muy simple. Se puede aplicar dentro de una metrica de distancia como `JaccardIndex` o `CosineSimilarity` para darle m√°s poder a la busqueda, dismunir el riesgo de no encontrar las palabras a censurar y aumentar la posibilidad de censurar las palabras que son por el hecho de estar limpias.


Veamos algunos ejemplos:

```python
from spanlp.domain.strategies import Preprocessing, TextToLower

strategies = [TextToLower()] # Defino mis estrategias de limpieza o pre-procesamiento
data = "ESTARE EN MINUSCULA" # Tengo mis datos
result = Preprocessing(data=data, clean_strategies=strategies).clean() # Invoco a Preprocessing
print(result)

# salida: estare en minuscula
```

Tambien se puede as√≠:
```python
from spanlp.domain.strategies import Preprocessing, TextToLower

strategies = [TextToLower()]
data = "ESTARE EN MINUSCULA" 
result = Preprocessing().clean(data=data, clean_strategies=strategies) # Envio los datos y las estragias al clean()
print(result)

# salida: estare en minuscula
```

Y tambien as√≠:
```python
from spanlp.domain.strategies import Preprocessing, TextToLower

strategies = [TextToLower()]
data = "ESTARE EN MINUSCULA"
preprocessor = Preprocessing(data=data, clean_strategies=strategies)
result = preprocessor.clean()
print(result)

# salida: estare en minuscula
```

Y as√≠:
```python
from spanlp.domain.strategies import Preprocessing, TextToLower

result = Preprocessing(data="ESTARE EN MINUSCULA", clean_strategies=[TextToLower()]).clean()
print(result)

# salida: estare en minuscula
```

**¬øC√≥mo aplico una estrategia para que pre-preprocese mis datos dentro de la m√©trica de distancia?**


Aplicar la metrica de distancia con una estrategia de pre-procesado:
```python
from spanlp.domain.strategies import JaccardIndex, TextToLower

strategies = [TextToLower()]
jaccard_index = JaccardIndex(normalize=True, clean_strategies=strategies)
result = jaccard_index.calculate("HOLA", "hola")

print(result)

# salida: 1
```

Usar la m√©trica como interface para ejecutar la estrategia:

```python
from spanlp.domain.strategies import JaccardIndex, TextToLower

strategies = [TextToLower()]
jaccard_index = JaccardIndex(normalize=True, clean_strategies=strategies)
result = jaccard_index.normalize("HOLA ME VOY A NORMALIZAR A MINUSCULA")

print(result)

# salida: hola me voy a normalizar a minuscula
```

**Usar varias estrategias de limpieza de datos**
Nota: Las estrategias se ejecutan en el orden enviado en la lista. Recomiendo analizar primero como desea que funcione: Si primero elimina espacios extras y despues elimina signos de puntuaci√≥n y luego stop words etc.. esto depender√° de su necesidad concreta; Por lo que se pueden obtener diferentes resultados si cambia el orden de las estrategias.

Enviando varias estrategias para limpiar mis datos:

```python
from spanlp.domain.strategies import Preprocessing, TextToLower, RemoveUserMentions, RemovePunctuation

strategies = [RemoveUserMentions(), TextToLower(), RemovePunctuation()]
tweet = "Hola @jhon, si viste que @freddy va a lanzar una nueva libreria Python para NLP?"
cleaned = Preprocessing().clean(data=tweet, clean_strategies=strategies)

print(cleaned)

#salida: hola  si viste que  va a lanzar una nueva libreria python para nlp
```

**Limpiemos emoticones, pronombres y pasemos a minuscula**

```python
from spanlp.domain.strategies import Preprocessing, RemoveEmoticons, TextToLower, RemovePronouns

strategies = [RemoveEmoticons(), TextToLower(), RemovePronouns()]
message = "Segun ella Los emoticones <3 :) :D ;) son muy usados y esta rosa tambien @}->--"
cleaned = Preprocessing().clean(data=message, clean_strategies=strategies)

print(cleaned)

# salida: segun los emoticones son muy usados y esta rosa tambien
```


## Testing
¬øEres tester? ¬øquieres automatizar pruebas? o ¬øsimplemente aprender del open source y de las pruebas? Aventurate ya y ayudame a mejorar este proyecto!
A continuaci√≥n encontrar√°s algunas pautas para implementar pruebas exitosas que permitar√°n encontrar posibles errores y mejoras.

### 1. ¬øPor donde empezar?
* Instalar python.
* Instalar la librer√≠a. Esto lo logras ejecutando en la terminal el comando: `pip install -i https://test.pypi.org/simple/ spanlp`
* Abre un nuevo script de python, importa la librer√≠a y empieza a experimentar.

### 2. ¬øQu√© tipos de pruebas puedo realizar?
Excelente pregunta! no hay limite para la creatividad; As√≠ que haz todas las pruebas que quieras e imagines. Sin embargo, aqu√≠ te dejo algunas pautas:

* **Pruebas de caja negra** => Una vez instales la librer√≠a y hayas leido la documentaci√≥n; Trata de usarla sin preocuparte como funciona o como obtuvo el resultado (Las pruebas no se hacen en base al c√≥digo, sino a la interfaz); Eso si, valida que la salida o el resultado sea el que esperas. Te puedes guiar (pero no mucho) de las pruebas unitarias que est√°n en: `/spanlp/tests/test_palabrota.py`

* **Pruebas de caja blanca** => Si quieres vez como funciona la libreria, estas pruebas son las tuyas. Intenta entender la estructura, los algoritmos y flujos. Una vez los comprendas, "a dar palo", trata de quebar o romper la l√≥gica, observa y encuentra si hay posibles formas de hacer que falle, prueba diferentes parametros, flujos, tipos de datos. Haz que falle, haz que se ponga lento! y me cuentas. ;)

* **Pruebas de carga y stress** => Si lo tuyo son las pruebas de requisitos no funcionales, te invito a que sigas estos pasos para estresar la libreria y medir que tan escalable es frente a procesos de alta carga, mide la velocidad y que tan bien se comparta con miles o millones de hilos usandola al tiempo.

Sigue estos pasos:

1. Crear una API Rest s√∫per simple. Crea el siguiente script y ll√°malo `server.py` 

```console
pip install flask
```

```python
from flask_cors import CORS, cross_origin
from flask import request
from flask import json

from spanlp.palabrota import Palabrota

app = Flask(__name__)
cors = CORS(app)

@app.route('/api/v1/nlp/text/censor', methods = ['POST'])
@cross_origin()
def censor():
    try:
        body = request.json     
        in_message = body['message']
        
        if in_message and len(str(in_message).strip()):
            palabrota = Palabrota()
            censored = palabrota.censor(in_message)
            response = {
                "success": True,
                "message": "OK",
                "error_code": 0,
                "data": {
                    'message': in_message,
                    'censored': censored
                }
            }
            return response
        else:
            return {
                "success": False,
                "message": "Bad Request - message is required",
                "error_code": 400,
                "data": {}
            }
    except Exception as e:
        return {
            "success": False,
            "message": "Internal Server Error - "+str(e),
            "error_code": 500,
            "data": {}
        }


if __name__ == '__main__':
    app.run(host='127.0.0.1', port=8080, debug=True)
```


```
python server.py
```

y listo!! 


2. Consume la API desde alg√∫n cliente http como [Postman](https://www.postman.com/), [Insomnia](https://insomnia.rest/download/) y/o [SOAP UI](https://www.soapui.org/). Tambien puedes usar alguna herramienta como [Apache JMeter](https://jmeter.apache.org/); o tambien puedes crear un script python con muchos hilos que consuma la API.


### 3. ¬øquieres escibrir unit tests y ejecutarlo de forma autom√°tica?
Clona el repositorio en tu m√°quina, abre el proyecto en tu editor favorito, ve al archivo `/spanlp/tests/test_palabrota.py` y empieza a escribir tus propios tests unitarios. Escribe cuantos quieras.
Una vez tengas los tests listos, ejecuta el siguiente comando en la raiz del proyecto (`/spanlp/`):

```console
pytest -ra
```

o tambien el comando:

```
python -m pytest
```

Esto ejecutar√° de forma autom√°tica todas las pruebas programadas e indicar√° si alg√∫n test fall√≥.


## Reportar un bug
Si encuentras alg√∫n problema (por muy m√≠nimo que sea) reportalo [aqu√≠](https://github.com/jfreddypuentes/spanlp/issues/new). Solo necesitar√°s poner t√≠tulo y describir la falla y aportar√° un mont√≥n a que este proyecto mejore su calidad.


## Contacto
¬øAlguna duda? escribeme por email:  [jfredypuentes@gmail.com](mailto:jfredypuentes@gmail.com)

Cuentame en ([@jfreddypuentes](https://twitter.com/jfreddypuentes)) ¬øqu√© te parece est√° librer√≠a? ¬øc√≥mo la est√°s usando? ¬øQu√© le mejorar√≠as?

<br>

## Contribuidorxs
* [@vivianamarquez](https://github.com/vivianamarquez) en Github, [@vivmarquez](https://twitter.com/vivmarquez) en Twitter (Data Scientist) - Contribuci√≥n al dise√±o y funcionalidades de la librer√≠a.
* [@normacalamartinez](https://github.com/normacalamartinez) en Github (BI Developer) - Contribuci√≥n al dataset de vulgaridades por pa√≠s de habla hispana.

<br>


**Hecho con ‚ù§Ô∏èÔ∏è de Colombia para el mundo.**
